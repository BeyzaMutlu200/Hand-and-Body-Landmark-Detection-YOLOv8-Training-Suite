# Hand & Holistic Landmark Detection + YOLOv8 Pipeline

This repository contains scripts to **collect hand and body landmark datasets**, **train a YOLOv8 model**, and **perform real-time detection**.
It is designed for applications like **gesture recognition, liveness detection, and hand pose estimation**.

**Note:** The scripts may appear similar in structure, but each serves a different purpose and allows you to create and test datasets in multiple ways. You can experiment with them to generate datasets that best fit your needs.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€ hand.py             # Collect hand landmarks and save images + YOLO-format txt
â”œâ”€ ds_landmark.py      # Collect holistic landmarks (face + body)
â”œâ”€ hand_dataset.py     # Preprocess hand images and landmarks for dataset creation
â”œâ”€ detect.py           # Real-time detection script for trained YOLOv8 model
â”œâ”€ split_data.py       # Split dataset into train/val/test and create data.yaml
â”œâ”€ yolo.py             # Train YOLOv8 model
â”œâ”€ test.py             # Real-time detection using trained YOLOv8 model
â”œâ”€ dataset/
â”‚  â”œâ”€ all/             # Original images + labels
â”‚  â”œâ”€ SplitData/       # YOLO-ready train/val/test folders
â”‚  â”‚  â”œâ”€ train/
â”‚  â”‚  â”‚  â”œâ”€ images/
â”‚  â”‚  â”‚  â””â”€ labels/
â”‚  â”‚  â”œâ”€ val/
â”‚  â”‚  â”‚  â”œâ”€ images/
â”‚  â”‚  â”‚  â””â”€ labels/
â”‚  â”‚  â””â”€ test/
â”‚  â”‚     â”œâ”€ images/
â”‚  â”‚     â””â”€ labels/
â””â”€ yaml/
   â””â”€ data.yaml         # YOLO dataset config
```

---

## 1ï¸âƒ£ hand.py â€“ Hand Landmark Dataset Collection

**Purpose:**
Capture hand images and landmarks from webcam, save images and YOLO-format annotation files.

**How it works:**

* Uses **MediaPipe Hands** to detect hand landmarks.
* Normalizes landmarks to `[0,1]` for YOLO-style annotations.
* Saves each frame as:

  * `.jpg` image
  * `.txt` annotation file in format: `class_id x y w h`

**Notes / Improvements:**

* Currently `w` and `h` are fixed (0.01), real bounding boxes can be computed from landmarks.
* Optionally filter out blurry frames using Laplacian variance.
* Ignore frames where the hand is mostly out-of-frame.

---

## 2ï¸âƒ£ hand\_dataset.py â€“ Hand Dataset Preprocessing

**Purpose:**
Prepare collected hand images and annotations for YOLO training.

**How it works:**

* Reads raw hand images and `.txt` landmark files.
* Performs normalization, cropping, and resizing as required.
* Ensures proper alignment of `.jpg` and `.txt` files.
* Saves processed dataset in `SplitData` format ready for YOLO.

---

## 3ï¸âƒ£ ds\_landmark.py â€“ Holistic Landmark Collection

**Purpose:**
Capture face + full-body landmarks for advanced gesture/liveness detection datasets.

**How it works:**

* Uses **MediaPipe Holistic** to detect:

  * Face landmarks
  * Pose landmarks
* Normalizes all landmarks to `[0,1]` coordinates.
* Saves images and `.txt` files for each frame.

**Notes:**

* Can be combined with hand landmarks for richer datasets.
* Ensure camera captures full body for consistent pose landmarks.

---

## 4ï¸âƒ£ split\_data.py â€“ Dataset Split & YOLO Preparation

**Purpose:**
Split dataset into **train, validation, and test** sets, and prepare folder structure and YOLO `data.yaml`.

**How it works:**

* Reads `.jpg` and `.txt` files from the dataset folder.
* Shuffles and splits files based on `SPLIT_DATA` ratios (default: 70% train, 20% val, 10% test).
* Creates folders:

  ```
  SplitData/train/images
  SplitData/train/labels
  SplitData/val/images
  SplitData/val/labels
  SplitData/test/images
  SplitData/test/labels
  ```
* Generates `data.yaml` for YOLOv8.

---

## 5ï¸âƒ£ yolo.py â€“ YOLOv8 Training

**Purpose:**
Train YOLOv8 model on the prepared dataset.

**How it works:**

* Loads a YOLOv8 model (e.g., `yolov8n.pt`).
* Uses `data.yaml` to know where train/val/test images and labels are.
* Trains for a set number of epochs (`epochs=10` in example).

**Output:**

* Trained weights: `runs/detect/train/weights/best.pt`
* Training logs and metrics.

---

## 6ï¸âƒ£ detect.py â€“ Real-Time Detection

**Purpose:**
Run real-time detection with the trained YOLOv8 model.

**How it works:**

* Loads the trained weights.
* Captures frames from webcam.
* Performs detection and draws bounding boxes, class labels, and confidence scores.
* Press `q` to exit.

---

## 7ï¸âƒ£ test.py â€“ Alternative Real-Time Test

**Purpose:**
Test the trained YOLOv8 model in real-time with webcam feed.

**How it works:**

* Loads `best.pt` trained weights.
* Captures webcam frames.
* Performs detection and draws bounding boxes, class labels, confidence scores.
* Press `q` to exit.

---

## ğŸ”§ Installation & Requirements

```bash
pip install opencv-python mediapipe ultralytics numpy
```

* Python 3.8+ recommended.
* GPU recommended for YOLO training but not required for dataset collection.

---

## ğŸ–¥ Usage (Terminal / Copyable)

```bash
# 1ï¸âƒ£ Collect hand landmarks
python hand.py

# 2ï¸âƒ£ Preprocess hand dataset
python hand_dataset.py

# 3ï¸âƒ£ Collect holistic landmarks (optional)
python ds_landmark.py

# 4ï¸âƒ£ Split dataset into train/val/test and prepare YOLO format
python split_data.py

# 5ï¸âƒ£ Train YOLOv8 model
python yolo.py

# 6ï¸âƒ£ Run real-time detection (alternative)
python detect.py

# 7ï¸âƒ£ Test YOLOv8 model in real-time using webcam
python test.py
```

---

## ğŸ¯ Purpose

* Build **high-quality hand and holistic landmark datasets**.
* Train **YOLOv8 models** for hand gesture recognition and liveness detection.
* Test and validate models **in real-time**.
* **Note:** These scripts are similar in structure, but each is intended for experimentation. You can modify, combine, and run them to create datasets tailored to your needs and test your model performance in different scenarios.
